---
title: "p8105_hw2_dl3757"
author: "Dang Lin dl3757"
date: "2024-10-02"
output:
 pdf_document: default
---

```{r, message = FALSE}
# Import the libraries
library(tidyverse)
library(readxl)
```

# Problem 1
```{r, message = FALSE}
# Read the csv file and clean the dataset
nyc_transit <- read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
                        na = c("NA", ".", "")) %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, 
         station_longitude, route1:route11, entry, vending, 
         entrance_type, ada) %>% 
  mutate(across(starts_with("route"), as.character)) %>%
  mutate(entry = case_match(entry, "YES" ~ TRUE, "NO" ~ FALSE))
```

Firstly, we read the CSV file and applied the janitor::clean_names() function to make all the variable names tidy and consistent in format. Next, we used the select() function to choose the necessary variables from the original dataset and rearranged the position of each column. After that, we converted all the route columns to character variables. Finally, we transformed the "entry" variable from a character to a logical variable using the case_match() function. After these data-cleaning steps, the dataset contains 1,868 observations and 19 variables, meaning the cleaned dataset has 1,868 rows and 19 columns. For instance, variables such as "station_name," "line," "station_latitude," "station_longitude," and different routes are included. This dataset is not entirely tidy because it contains a lot of missing values, which we may need to address by removing some of them depending on the analysis. Additionally, some route variables were not initially in the correct format, so converting them to character variables was necessary before performing further analysis.

```{r}
# The number of distinct stations
distinct_station <- nyc_transit %>% 
  distinct(station_name, line)

nrow(distinct_station)
```

There are 465 distinct stations.

```{r}
# The number of distinct ADA-compliant stations
ada_compliant_station <- nyc_transit %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name, line)

nrow(ada_compliant_station)
```

There are 84 ADA-compliant stations.

```{r}
# The proportion of stations entrances/exits without vending allow entrance
nyc_transit %>%  
  filter(vending == "NO") %>%  
  pull(entry) %>%  
  mean()
```

The proportion of station entrances/exits without vending allow entrance is 0.3770492.

```{r}
# The number of distinct stations serve the A train
distinct_A <- nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  distinct(station_name, line)

nrow(distinct_A)
```

Sixty distinct stations serve the A train.

```{r}
# The number of distinct stations that are ADA-compliant serve the A train
distinct_A_ada <- nyc_transit %>%  
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>%  
  filter(route == "A", ada == TRUE) %>%  
  distinct(station_name, line)

nrow(distinct_A_ada)
```

Of these 60 distinct stations that serve the A train, 17 stations are ADA-compliant.

# Problem 2
```{r}
# Load and clean the dataset "Mr. Trash Wheel"
mr_trash_wheel <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
                          sheet = "Mr. Trash Wheel", range = "A2:N655") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, 0))) %>% 
  mutate(year = as.character(year)) %>% 
  mutate(sheet = "Mr.")
```

```{r}
# Load and clean the dataset "Professor Trash Wheel"
professor_trash_wheel <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
                          sheet = "Professor Trash Wheel", range = "A2:M123") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(year = as.character(year)) %>% 
  mutate(sheet = "Professor")
```

```{r}
# Load and clean the dataset "Gwynnda Trash Wheel"
gwynnda_trash_wheel <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
                          sheet = "Gwynnda Trash Wheel", range = "A2:L266") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(year = as.character(year)) %>% 
  mutate(sheet = "Gwynnda")
```

```{r}
# Produce a single tidy dataset by merging different datasets
tidy_dataset = 
  bind_rows(mr_trash_wheel, professor_trash_wheel, 
            gwynnda_trash_wheel) %>%
  janitor::clean_names() %>% 
  select(sheet, everything())
```

After a series of data cleaning steps, the Mr. Trash Wheel dataset contains 651 observations and 15 variables, the Professor Trash Wheel dataset incorporates 119 observations and 14 variables, and the Gwynnda Trash Wheel dataset includes 263 observations and 13 variables. It is worth mentioning that most of the values in the "Wrappers" column of the Gwynnda Trash Wheel dataset are listed as "NA". However, we did not omit the rows without values for "Wrappers" because doing so would result in the loss of many informative observations. Subsequently, we combined the three datasets into one to perform a more comprehensive analysis. The resulting tidy dataset contains 1033 observations and 15 variables, with each observation labeled according to its source sheet. This combined dataset includes important variables such as "weight_tons", "volume_cubic_yards", "plastic_bottles", and others, with data collected between 2014 and 2024. The total weight of trash collected by Professor Trash Wheel is `r sum(tidy_dataset$weight_tons[tidy_dataset$sheet == "Professor"], na.rm = TRUE)` based on available data. Moreover, the total number of cigarette butts collected by Gwynnda in June of 2022 is `r sum(tidy_dataset$cigarette_butts[tidy_dataset$sheet == "Gwynnda" & format(tidy_dataset$date, "%Y-%m") == "2022-06"])`.

# Problem 3
```{r message = FALSE}
# Load and clean the dataset
bakers <- read_csv("/Users/apple/Desktop/P8105_hw2_dl3757/gbb_datasets/bakers.csv") %>%
  janitor::clean_names() %>% 
  mutate(baker = sub(" .*", "", baker_name)) %>% 
  select(baker, everything(), -baker_name) %>% 
  arrange(baker)

bakes <- read_csv("/Users/apple/Desktop/P8105_hw2_dl3757/gbb_datasets/bakes.csv") %>%
  janitor::clean_names() %>% 
  select(baker, series, everything()) %>% 
  arrange(baker)

results <- read_csv("/Users/apple/Desktop/P8105_hw2_dl3757/gbb_datasets/results.csv", 
                    skip = 2) %>%
  janitor::clean_names() %>% 
  arrange(baker)
```

```{r}
# Check for completeness and correctness
bakers_bakes <- anti_join(bakers, bakes, by = "baker")

bakes_results <- anti_join(bakes, results, by = c("series", "episode"))
```